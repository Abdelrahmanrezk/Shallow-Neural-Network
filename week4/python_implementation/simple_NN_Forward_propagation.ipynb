{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This will be simple example of application in NN\n",
    "\n",
    "This example will take you on different stages and step by step of applying Forward Propagation\n",
    "We will use simple data created with numpy array to make it clear and just one output 0 or 1.\n",
    "\n",
    "**The goal of this to get intuition of how NN work from scratch as Forward Propagation pass**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters\n",
    "The weights of each layer depends on the neurons in this layer and in the previous layer, so we need to know number of layers and for each layer whats number of neurons.\n",
    "\n",
    "Our NN will be three layers first one input layer with 4 features, second will be hidden layer with 5 neutrons, last output layer with 1 neurons.\n",
    "\n",
    "![alt neural_network](images/art-neural-network-image001.png \"neural_network\")\n",
    "\n",
    "For each layer will add the bias term which x0\n",
    "\n",
    "The weights paramters will be for hidden and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(num_layers, layer_nerons):\n",
    "    '''\n",
    "    Argument:\n",
    "        num_layers is number of layer in our example 3\n",
    "        layer_nerons for each layer the number of nerons it has which for input layer 4, hidden layer 5, output 1.\n",
    "    '''\n",
    "    paramters = {}\n",
    "    for i in range(1, num_layers): # because weights start from hidden layer\n",
    "        # we will conside the bias unit x0 and for it theta0\n",
    "        paramters[\"W_of_L\" + str(i)] = np.random.rand(layer_nerons[i], layer_nerons[i-1]+1) # +1 which bias theta0\n",
    "    return paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramters = initialize_parameters(3, [4,5,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the weights of each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of layer W_of_L1 (5, 5)\n",
      "==================================================\n",
      "The weights:  [[0.99469949 0.56124693 0.43669091 0.03250644 0.49159484]\n",
      " [0.10448778 0.37636426 0.20017649 0.58980759 0.88498602]\n",
      " [0.91657882 0.05172016 0.67387842 0.11711225 0.50199679]\n",
      " [0.65713119 0.9538917  0.90339166 0.45596905 0.69116416]\n",
      " [0.95982899 0.78951523 0.16523729 0.80916132 0.61281737]]\n",
      "The shape of layer W_of_L2 (1, 6)\n",
      "==================================================\n",
      "The weights:  [[0.17187488 0.88361522 0.6816279  0.88431436 0.35966439 0.55101178]]\n"
     ]
    }
   ],
   "source": [
    "for i in paramters:\n",
    "    print(\"The shape of layer \" + i +\" \" + str(paramters[i].shape))\n",
    "    print(\"=\" * 50)\n",
    "    print(\"The weights: \", paramters[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    '''\n",
    "    Argument:\n",
    "        z = x*theta\n",
    "    '''\n",
    "# np.log is natural log of base 2 which is called ln\n",
    "    g_z = 1/(1+np.exp(-z))\n",
    "    return g_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement feed forward propagation\n",
    "\n",
    "first process of NN is to going forward for each layer to the last layer then go back to first layer using back propagation so first we need to going forward propagation.\n",
    "\n",
    "Remember Forward propagation :\n",
    "\n",
    "![alt neural_network](images/forward.png \"forward propagation\")\n",
    "\n",
    "\n",
    "![alt neural_network](images/feed_process.png \" feed_process\")\n",
    "\n",
    "**Then we get error for last layer to go back for back propagation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_model(x):\n",
    "    '''\n",
    "    Argument:\n",
    "        x the input example with features of each example in our case 7 examples and 4 features\n",
    "    '''\n",
    "    m,n = x.shape # number of training examples and number of features\n",
    "    \n",
    "    cashes_z = {}\n",
    "    cashes_a = {}\n",
    "    \n",
    "    paramters = initialize_parameters(3, [4,5,1]) # call the paramters function\n",
    "    \n",
    "    # first layer\n",
    "    act_1 = x\n",
    "    act_1 = np.hstack((np.ones((x.shape[0], 1)), act_1)) # add column of 1 to X which x0=1\n",
    "    \n",
    "    # Second layer\n",
    "    Z_2 = np.matmul(act_1, paramters[\"W_of_L\" + str(1)].T)\n",
    "    cashes_z['Z_2'] = Z_2\n",
    "    Act_2 = sigmoid(Z_2)\n",
    "    cashes_a['Act_2'] = Act_2\n",
    "    Act_2 = np.hstack((np.ones((Act_2.shape[0], 1)), Act_2)) # add column of 1 to X which x0=1\n",
    "    \n",
    "   # Third layer\n",
    "    Z_3 =  np.matmul(Act_2, paramters[\"W_of_L\" + str(2)].T)\n",
    "    cashes_z['Z_3'] = Z_3\n",
    "    Act_3 = sigmoid(Z_3)\n",
    "    cashes_a['Act_3'] = Act_3\n",
    "    \n",
    "    return cashes_z, cashes_a\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input examples with features: (7, 4)\n",
      "The shape of outpur for each example: (7,)\n"
     ]
    }
   ],
   "source": [
    "# create 7 random examples  with 4 features\n",
    "# for each example create its output\n",
    "x = np.random.rand(7,4)\n",
    "y = np.array([1,1,1,0,0,1,1])\n",
    "print(\"The shape of input examples with features:\", x.shape)\n",
    "print(\"The shape of outpur for each example:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cashes_z, cashes_a = feed_forward_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Z_2': array([[1.84778827, 2.55567935, 0.79803833, 1.49875772, 1.03572863],\n",
       "        [1.82512073, 2.18310973, 0.61177178, 1.38992818, 1.21975897],\n",
       "        [1.86768925, 2.18742578, 0.65059624, 1.38900061, 1.13836353],\n",
       "        [1.8870714 , 2.37446113, 0.89388233, 1.47639265, 1.28396313],\n",
       "        [1.2266141 , 1.81382495, 0.56058438, 1.20987575, 0.73470253],\n",
       "        [1.93510164, 2.39844794, 0.93516256, 1.4695626 , 1.06323294],\n",
       "        [1.63776806, 1.69025772, 0.50319851, 1.20940719, 0.99525901]]),\n",
       " 'Z_3': array([[2.79689758],\n",
       "        [2.76160779],\n",
       "        [2.76023173],\n",
       "        [2.84601833],\n",
       "        [2.62541475],\n",
       "        [2.82499705],\n",
       "        [2.66255842]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cashes_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Act_2': array([[0.86386721, 0.92795413, 0.6895547 , 0.81738912, 0.738025  ],\n",
       "        [0.86117944, 0.89872247, 0.64834486, 0.80058078, 0.77202113],\n",
       "        [0.86619068, 0.89911465, 0.65714481, 0.80043265, 0.75737906],\n",
       "        [0.86842125, 0.91485899, 0.7096907 , 0.81402709, 0.78312363],\n",
       "        [0.77322541, 0.85982352, 0.63658774, 0.77027696, 0.67583636],\n",
       "        [0.87381302, 0.91670887, 0.71812148, 0.81299089, 0.74330788],\n",
       "        [0.83723101, 0.84425805, 0.6232107 , 0.77019404, 0.73012542]]),\n",
       " 'Act_3': array([[0.94250794],\n",
       "        [0.94056558],\n",
       "        [0.94048861],\n",
       "        [0.9451125 ],\n",
       "        [0.93247943],\n",
       "        [0.94401177],\n",
       "        [0.93478082]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cashes_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
